% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{00A0}{\nobreakspace}
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}
\usepackage{appendix} \setcounter{tocdepth}{0}

\title{reduce Users Manual}
\date{June 24, 2015}
\release{X1.0.1}
\author{Kenneth Anderson}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\expandafter\def\csname PYG@tok@gd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gu\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@gt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@gs\endcsname{\let\PYG@bf=\textbf}
\expandafter\def\csname PYG@tok@gr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@cm\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@vg\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@m\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@cs\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@ge\endcsname{\let\PYG@it=\textit}
\expandafter\def\csname PYG@tok@vc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@il\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@go\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.20}{##1}}}
\expandafter\def\csname PYG@tok@cp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@gi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@ni\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.84,0.33,0.22}{##1}}}
\expandafter\def\csname PYG@tok@nl\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.13,0.44}{##1}}}
\expandafter\def\csname PYG@tok@nn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@no\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.38,0.68,0.84}{##1}}}
\expandafter\def\csname PYG@tok@na\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@nd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\expandafter\def\csname PYG@tok@ne\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\expandafter\def\csname PYG@tok@si\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.44,0.63,0.82}{##1}}}
\expandafter\def\csname PYG@tok@s2\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@vi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@nt\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.45}{##1}}}
\expandafter\def\csname PYG@tok@nv\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@s1\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@gp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@sh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ow\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sx\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@bp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c1\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@kc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@mf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@err\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PYG@tok@kd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@ss\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.32,0.47,0.09}{##1}}}
\expandafter\def\csname PYG@tok@sr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.14,0.33,0.53}{##1}}}
\expandafter\def\csname PYG@tok@mo\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@o\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@kr\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@s\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@kp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@w\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PYG@tok@kt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.56,0.13,0.00}{##1}}}
\expandafter\def\csname PYG@tok@sc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@k\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@se\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sd\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZam{\char`\&}
\def\PYGZlt{\char`\<}
\def\PYGZgt{\char`\>}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZhy{\char`\-}
\def\PYGZsq{\char`\'}
\def\PYGZdq{\char`\"}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index-latex::doc}



\chapter{Introduction}
\label{intro:introduction}\label{intro:reduce-users-manual}\label{intro::doc}
This document is version 1.0 of the \code{reduce} Users Manual. This manual will
describe the usage of \code{reduce} as an application provided by the Gemini Observatory
Astrodata package suite. \code{reduce} is an application that allows users to invoke the
Gemini Recipe System to perform data processing and reduction on one or more
astronomical datasets.

This document presents details on applying \code{reduce} to astronomical datasets,
currently defined as multi-extension FITS (MEF) files, both through the application's
command line interface and the application programming interface (API). Details and
information about the \code{astrodata} package, the Recipe System, and/or the data
processing involved in data reduction are beyond the scope of this document and
will only be engaged when directly pertinent to the operations of \code{reduce}.


\section{Reference Documents}
\label{intro:reference-documents}\begin{itemize}
\item {} 
\emph{The Gemini Recipe System: a dynamic workflow for automated data reduction},
K. Labrie \emph{et al}, SPIE, 2010.

\item {} 
\emph{Developing for Geminiâ€™s extensible pipeline environment}, K. Labrie,
C. Allen, P. Hirst, ADASS, 2011

\item {} 
\emph{Gemini's Recipe System; A publicly available instrument-agnostic pipeline
infrastructure}, K. Labrie et al, ADASS 2013.

\end{itemize}


\section{Overview}
\label{intro:overview}
As an application, \code{reduce} provides interfaces to configure and launch the
Gemini Recipe System, a framework for developing and running configurable data
processing pipelines and which can accommodate processing pipelines for arbitrary
dataset types. In conjunction with the development of \code{astrodata}, Gemini
Observatory has also developed the compatible \code{astrodata\_Gemini} package, the
code base currently providing abstraction of, and processing for, Gemini
Observatory astronomical observations.

In Gemini Observatory's operational environment ``on summit,'' \code{reduce},
\code{astrodata}, and the \code{astrodata\_Gemini} packages provide a currently defined,
near-realtime, quality assurance pipeline, the so-called QAP. \code{reduce} is used
to launch this pipeline on newly acquired data and provide image quality metrics
to observers, who then assess the metrics and apply observational decisions on
telescope operations.

Users unfamiliar with terms and concepts heretofore presented should consult
documentation cited in the previous sections (working on the Recipe System User
Manual).


\section{Glossary}
\label{intro:glossary}\begin{quote}

\textbf{adcc} -- Automatated Data Communication Center. Provides XML-RPC and HTTP
services for pipeline operations. Can be run externally to \code{reduce.} Users
need not know about or invoke the \code{adcc} for \code{reduce} operations.
\code{reduce} will launch an \code{adcc} instance if one is not available. See
Sec. {\hyperref[discuss:adcc]{\emph{The adcc}}} for further discussion on \code{adcc}.

\textbf{astrodata} (or Astrodata) -- part of the \textbf{gemini\_python} package suite
that defines the dataset abstraction layer for the Recipe System.

\textbf{AstroData} -- not to be confused with \textbf{astrodata}, this is the main class
of the \code{astrodata} package, and the one most users and developers will
interact with at a programmatic level.

\textbf{AstroDataType} -- Represents a data classification. A dataset will be
classified by a number of types that describe both the data and its processing
state. The AstroDataTypes are hierarchical, from generic to specific.  For
example, a typical unprocessed GMOS image would have a set of types like

`GMOS\_S', `GMOS\_IMAGE', `GEMINI', `SIDEREAL', `IMAGE', `GMOS', `GEMINI\_SOUTH',
`GMOS\_RAW', `UNPREPARED', `RAW' (see \textbf{types} below).

\textbf{astrodata\_Gemini} -- the \textbf{gemini\_python} package that provides all
observatory specific definitions of data types, \textbf{recipes}, and associated
\textbf{primitives} for Gemini Observatory data.

\textbf{astrodata\_X} -- conceivably a data reduction package that could reduce
other observatory and telescope data. Under the Astrodata system, it is
entirely possible for the Recipe System to process HST or Keck data, given
the development of an associated package, astrodata\_HST or astrodata\_Keck.
Pipelines and processing functions are defined for the particulars of each
telescope and its various instruments.

\textbf{Descriptor} -- Represents a high-level metadata name. Descriptors allow
access to essential information about the data through a uniform,
instrument-agnostic interface to the FITS headers.

\textbf{gemini\_python} -- A suite of packages comprising \textbf{astrodata},
\textbf{astrodata\_Gemini}, \textbf{astrodata\_FITS}, and \textbf{gempy}, all of which provide
the full functionality needed to run \textbf{Recipe System}  pipelines on
observational datasets.

\textbf{gempy} -- a \textbf{gemini\_python} package comprising functional utilities to
the \textbf{astrodata\_Gemini} package.

\textbf{MEF} -- Multiple Extension FITS, the standard data format not only for
Gemini Observatory but many observatories.

\textbf{primitive} -- A function defined within an \textbf{astrodata\_{[}X{]}} package that
performs actual work on the passed dataset. Primitives observe tightly
controlled interfaces in support of re-use of primitives and recipes for
different types of data, when possible. For example, all primitives called
\code{flatCorrect} must apply the flat field correction appropriate for the dataâ€™s
current AstroDataType, and must have the same set of input parameters.  This
is a Gemini Coding Standard, it is not enforced by the Recipe System.

\textbf{recipe} -- Represents the sequence of transformations. A recipe is a
simple text file that enumerates the set and order of \textbf{primitives} that will
process the passed dataset. A \textbf{recipe} is the high-level pipeline definition.
Users can pass recipe names directly to reduce. Essentially, a recipe is a
pipeline.

\textbf{Recipe System} -- The gemin\_python framework that accommodates an arbitrary
number of defined recipes and the primitives

\textbf{reduce} -- The user/caller interface to the Recipe System and its associated
recipes/pipelines.

\textbf{subrecipe} -- Shorter recipe called like a primitive by a recipe or another
subrecipe.  The subrecipes are not part of the main recipe index, they are more
akin in purpose to primitives than to recipes.

\textbf{type} or \textbf{typeset} --  Not to be confused with language primitive or
programmatic data types, these are data types defined within an
\textbf{astrodata\_{[}X{]}} package used to describe the kind of observational data that
has been passed to the Recipe System., Eg., GMOS\_IMAGE, NIRI. In this document,
these terms are synonymous with \textbf{AstroDataType} unless otherwise indicated.
\end{quote}


\chapter{Installation}
\label{userenv:installation}\label{userenv::doc}
The \code{astrodata} package has several dependencies like \code{numpy}, \code{astropy},
and others. All dependencies of \code{gemini\_python} and \code{astrodata} are provide by
the Ureka package, and users are highly encouraged to install and use this very
useful package. It is an easy and, perhaps, best way to get everything you need
and then some. Ureka is available at \href{http://ssb.stsci.edu/ureka/}{http://ssb.stsci.edu/ureka/}.

WARNING:  The Ureka installation script will not set up IRAF for you. You need to do
that yourself. Here's how:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} cd \PYGZti{}
\PYGZdl{} mkdir iraf
\PYGZdl{} cd iraf
\PYGZdl{} mkiraf
\PYGZhy{}\PYGZhy{} creating a new uparm directory
Terminal types: xgterm,xterm,gterm,vt640,vt100,etc.
Enter terminal type: xgterm
A new LOGIN.CL file has been created in the current directory.
You may wish to review and edit this file to change the defaults.
\end{Verbatim}

Once a user has has retrieved the gemini\_python package, available as a tarfile
from the Gemini website (\href{http://gemini.edu}{http://gemini.edu}), and untarred only minor adjustments
need to be made to the user environment in order to make astrodata importable and
allow \code{reduce} to work properly.


\section{Install}
\label{userenv:config}\label{userenv:install}

\subsection{Recommended Installation}
\label{userenv:recommended-installation}
It is recommended to install the software in a location other than the standard
python location for modules (the default \code{site-packages}). This is also the
only solution if you do not have write permission to the default \code{site-packages}.
Here is how you install the software somewhere other than the default location:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} python setup.py install \PYGZhy{}\PYGZhy{}prefix=/your/favorite/location
\end{Verbatim}

\code{/your/favorite/location} must already exist.  This command will install executable
scripts in a \code{bin} subdirectory, the documentation in a \code{share} subdirectory,
and the modules in a \code{lib/python2.7/site-packages} subdirectory.  The modules being
installed are \code{astrodata}, \code{astrodata\_FITS}, \code{astrodata\_Gemini}, and \code{gempy}.
In this manual, we will only use \code{astrodata}.

Because you are not using the default location, you will need to add two paths to
your environment.  You might want to add the following to your .cshrc or
.bash\_profile, or equivalent shell configuration script.

C shell(csh, tcsh):

\begin{Verbatim}[commandchars=\\\{\}]
setenv PATH /your/favorite/location/bin:\PYGZdl{}\PYGZob{}PATH\PYGZcb{}
setenv PYTHONPATH /your/favorite/location/lib/python2.7/site\PYGZhy{}packages:\PYGZdl{}\PYGZob{}PYTHONPATH\PYGZcb{}
\end{Verbatim}

Bourne shells (sh, bash, ksh, ...)

\begin{Verbatim}[commandchars=\\\{\}]
export PATH=/your/favorite/location/bin:\PYGZdl{}\PYGZob{}PATH\PYGZcb{}
export PYTHONPATH=/your/favorite/location/lib/python2.7/site\PYGZhy{}packages:\PYGZdl{}\PYGZob{}PYTHONPATH\PYGZcb{}
\end{Verbatim}

If you added those lines to your shell configuration script, make sure your
\code{source} the file to activate the new setting.

For csh/tcsh:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} source \PYGZti{}/.cshrc
\PYGZdl{} rehash
\end{Verbatim}

For bash:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} source \PYGZti{}/.bash\PYGZus{}profile
\end{Verbatim}


\subsection{Installation under Ureka}
\label{userenv:installation-under-ureka}
Assuming that you have installed Ureka and that you have write access to the Ureka
directory, this will install \code{astrodata} in the Ureka \code{site-packages} directory.
WARNING: While easier to install and configure, this will modify your Ureka
installation.

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} python setup.py install
\end{Verbatim}

This will also add executables to the Ureka \code{bin} directory and documentation to
the Ureka \code{share} directory.

With this installation scheme, there is no need to add paths to your environment.
However, it is a lot more complicated to remove the Gemini software in case of
problems, or if you just want to clean it out after evaluation.

In tcsh, you will need to run \code{rehash} to pick the new executables written to
\code{bin}.


\section{Test the installation}
\label{userenv:test}\label{userenv:test-the-installation}
Start up the python interpreter and import astrodata:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} python
\PYGZgt{}\PYGZgt{}\PYGZgt{} import astrodata
\end{Verbatim}

Next, return to the command line and test that \code{reduce} is reachable
and runs. There may be some delay as package modules are byte compiled:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce \PYGZhy{}h
\end{Verbatim}

or

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce [\PYGZhy{}\PYGZhy{}help]
\end{Verbatim}

This will print the reduce help to the screen.

If users have Gemini fits files available, they can test that the Recipe System
is functioning as expected with a test recipe provided by the astrodata\_Gemini
package:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce \PYGZhy{}\PYGZhy{}recipe test\PYGZus{}one /path/to/gemini\PYGZus{}data.fits
\end{Verbatim}

If all is well, users will see something like:

\begin{Verbatim}[commandchars=\\\{\}]
Resetting logger for application: reduce
Logging configured for application: reduce
                       \PYGZhy{}\PYGZhy{}\PYGZhy{} reduce, v4890  \PYGZhy{}\PYGZhy{}\PYGZhy{}
              Running under astrodata Version GP\PYGZhy{}X1
All submitted files appear valid
Starting Reduction on set \PYGZsh{}1 of 1

  Processing dataset(s):
        gemini\PYGZus{}data.fits

==============================================================================
RECIPE: test\PYGZus{}one
==============================================================================
 PRIMITIVE: showParameters
 \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
 rtf = False
 suffix = \PYGZsq{}\PYGZus{}scafaasled\PYGZsq{}
 otherTest = False
 logindent = 3
 logfile = \PYGZsq{}reduce.log\PYGZsq{}
 reducecache = \PYGZsq{}.reducecache\PYGZsq{}
 storedcals = \PYGZsq{}calibrations/storedcals\PYGZsq{}
 index = 1
 retrievedcals = \PYGZsq{}calibrations/retrievedcals\PYGZsq{}
 cachedict = \PYGZob{}\PYGZsq{}storedcals\PYGZsq{}: \PYGZsq{}calibrations/storedcals\PYGZsq{}, \PYGZsq{}retrievedcals\PYGZsq{}:
              \PYGZsq{}calibrations/retrievedcals\PYGZsq{}, \PYGZsq{}calibrations\PYGZsq{}: \PYGZsq{}calibrations\PYGZsq{},
              \PYGZsq{}reducecache\PYGZsq{}: \PYGZsq{}.reducecache\PYGZsq{}\PYGZcb{}
 loglevel = \PYGZsq{}stdinfo\PYGZsq{}
 calurl\PYGZus{}dict = \PYGZob{}\PYGZsq{}CALMGR\PYGZsq{}: \PYGZsq{}http://fits/calmgr\PYGZsq{},
                \PYGZsq{}UPLOADPROCCAL\PYGZsq{}: \PYGZsq{}http://fits/upload\PYGZus{}processed\PYGZus{}cal\PYGZsq{},
                \PYGZsq{}QAMETRICURL\PYGZsq{}: \PYGZsq{}http://fits/qareport\PYGZsq{},
                \PYGZsq{}QAQUERYURL\PYGZsq{}: \PYGZsq{}http://fits/qaforgui\PYGZsq{},
                \PYGZsq{}LOCALCALMGR\PYGZsq{}: \PYGZsq{}http://localhost:\PYGZpc{}(httpport)d/calmgr/\PYGZpc{}(caltype)s\PYGZsq{}\PYGZcb{}
 logmode = \PYGZsq{}standard\PYGZsq{}
 test = True
 writeInt = False
 calibrations = \PYGZsq{}calibrations\PYGZsq{}
 .
Wrote gemini\PYGZus{}data.fits in output directory


reduce completed successfully.
\end{Verbatim}

Users curious about the URLs in the example above, i.e. \code{http://fits/...}, see
Sec. {\hyperref[discuss:fitsstore]{\emph{Fits Storage}}} in Chapter 5, Discussion.


\chapter{Interfaces}
\label{interfaces:interfaces}\label{interfaces::doc}

\section{Introduction}
\label{interfaces:introduction}
The \code{reduce} application provides a command line interface and an API, both
of which can configure and launch a Recipe System processing pipeline (a `recipe')
on the input dataset. Control of \code{reduce} and the Recipe System is provided
by a variety of options and switches. Of course, all options and switches
can be accessed and controlled through the API.


\section{Command line interface}
\label{interfaces:command-line-interface}
We begin with the command line help provided by \code{reduce -{-}help}, followed by
further description and discussion of certain non-trivial options that require
detailed explanation.

\begin{Verbatim}[commandchars=\\\{\}]
usage: reduce [options] fitsfile [fitsfile ...]
\end{Verbatim}

positional arguments:

\begin{Verbatim}[commandchars=\\\{\}]
fitsfile [fitsfile ...]
\end{Verbatim}

The {[}options{]} are described in the following sections.


\subsection{Informational switches}
\label{interfaces:informational-switches}\begin{description}
\item[{\textbf{-h, --help}}] \leavevmode
show the help message and exit

\item[{\textbf{-v, --version}}] \leavevmode
show program's version number and exit

\item[{\textbf{-d, --displayflags}}] \leavevmode
Display all parsed option flags and exit.

When specified, this switch will present the user with a table of all
parsed arguments and then exit without running. This allows the user to
check that the configuration is as intended. The table provides a convenient
view of all passed and default values. Unless a user has specified a
recipe (-r, --recipe), `recipename' indicates `None' because at this point,
the Recipe System has not yet been engaged and a default recipe not yet
determined.

Eg.,:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce \PYGZhy{}d \PYGZhy{}\PYGZhy{}logmode console fitsfile.fits

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}   switches, vars, vals  \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

Literals                 var \PYGZsq{}dest\PYGZsq{}              Value
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
[\PYGZsq{}\PYGZhy{}\PYGZhy{}invoked\PYGZsq{}]            :: invoked              :: False
[\PYGZsq{}\PYGZhy{}\PYGZhy{}addprimset\PYGZsq{}]         :: primsetname          :: None
[\PYGZsq{}\PYGZhy{}d\PYGZsq{}, \PYGZsq{}\PYGZhy{}\PYGZhy{}displayflags\PYGZsq{}] :: displayflags         :: True
[\PYGZsq{}\PYGZhy{}p\PYGZsq{}, \PYGZsq{}\PYGZhy{}\PYGZhy{}param\PYGZsq{}]        :: userparam            :: None
[\PYGZsq{}\PYGZhy{}\PYGZhy{}logmode\PYGZsq{}]            :: logmode              :: [\PYGZsq{}console\PYGZsq{}]
[\PYGZsq{}\PYGZhy{}r\PYGZsq{}, \PYGZsq{}\PYGZhy{}\PYGZhy{}recipe\PYGZsq{}]       :: recipename           :: None
[\PYGZsq{}\PYGZhy{}\PYGZhy{}throw\PYGZus{}descriptor\PYGZus{}exceptions\PYGZsq{}] :: throwDescriptorExceptions :: False
[\PYGZsq{}\PYGZhy{}\PYGZhy{}logfile\PYGZsq{}]            :: logfile              :: reduce.log
[\PYGZsq{}\PYGZhy{}t\PYGZsq{}, \PYGZsq{}\PYGZhy{}\PYGZhy{}astrotype\PYGZsq{}]    :: astrotype            :: None
[\PYGZsq{}\PYGZhy{}\PYGZhy{}override\PYGZus{}cal\PYGZsq{}]       :: user\PYGZus{}cals            :: None
[\PYGZsq{}\PYGZhy{}\PYGZhy{}context\PYGZsq{}]            :: running\PYGZus{}contexts     :: None
[\PYGZsq{}\PYGZhy{}\PYGZhy{}calmgr\PYGZsq{}]             :: cal\PYGZus{}mgr              :: None
[\PYGZsq{}\PYGZhy{}\PYGZhy{}suffix\PYGZsq{}]             :: suffix               :: None
[\PYGZsq{}\PYGZhy{}\PYGZhy{}loglevel\PYGZsq{}]           :: loglevel             :: stdinfo
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

Input fits file(s):      fitsfile.fits
\end{Verbatim}

\end{description}


\subsection{Configuration Switches, Options}
\label{interfaces:configuration-switches-options}\label{interfaces:options}\begin{description}
\item[{\textbf{--addprimset \textless{}PRIMSETNAME\textgreater{}}}] \leavevmode
Add this path to user-supplied primitives for reduction. eg., path to a
primitives module.

\item[{\textbf{--calmgr \textless{}CAL\_MGR\textgreater{}}}] \leavevmode
This is a URL specifying a calibration manager service. A calibration manager
overides Recipe System table. Not available outside Gemini operations.

\item[{\textbf{--context \textless{}RUNNING\_CONTEXTS\textgreater{}}}] \leavevmode
Use \textless{}RUNNING\_CONTEXTS\textgreater{} for primitives sensitive to context. Eg.,
\code{-{-}context QA}. When not specified, the context defaults to `QA'.

\item[{\textbf{--invoked}}] \leavevmode
Boolean indicating that reduce was invoked by the control center.

\item[{\textbf{--logmode \textless{}LOGMODE\textgreater{}}}] \leavevmode
Set logging mode. One of
\begin{itemize}
\item {} 
standard

\item {} 
console

\item {} 
quiet

\item {} 
debug

\item {} 
null

\end{itemize}

where `console' writes only to screen and `quiet' writes only to the log
file. Default is `standard'.

\item[{\textbf{--logfile \textless{}LOGFILE\textgreater{}}}] \leavevmode
Set the log file name. Default is `reduce.log' in the current directory.

\item[{\textbf{--loglevel \textless{}LOGLEVEL\textgreater{}}}] \leavevmode
Set the verbose level for console logging. One of
\begin{itemize}
\item {} 
critical

\item {} 
error

\item {} 
warning

\item {} 
status

\item {} 
stdinfo

\item {} 
fullinfo

\item {} 
debug

\end{itemize}

Default setting is `stdinfo.'

\item[{\textbf{--override\_cal \textless{}USER\_CALS {[}USER\_CALS ...{]}\textgreater{}}}] \leavevmode
The option allows users to provide their own calibrations to \code{reduce}.
Add a calibration to User Calibration Service.
`--override\_cal CALTYPE:CAL\_PATH'
Eg.,

\code{-{-}override\_cal processed\_arc:wcal/gsTest\_arc.fits}

\item[{\textbf{-p \textless{}USERPARAM {[}USERPARAM ...{]}\textgreater{}, --param \textless{}USERPARAM {[}USERPARAM ...{]}\textgreater{}}}] \leavevmode
Set a primitive parameter from the command line. The form `-p par=val' sets
the parameter in the reduction context such that all primitives will `see' it.
The form

\code{-p ASTROTYPE:primitivename:par=val}

sets the parameter such that it applies only when the current reduction type
(type of current reference image) is `ASTROTYPE' and the primitive is
`primitivename'. Separate parameter-value pairs by whitespace:
(eg. `-p par1=val1 par2=val2')

See Sec. {\hyperref[interfaces:userpars]{\emph{Overriding Primitive Parameters}}}, for more information on these values.

\item[{\textbf{-r \textless{}RECIPENAME\textgreater{}, --recipe \textless{}RECIPENAME\textgreater{}}}] \leavevmode
Specify an explicit recipe to be used rather than internally determined by
a dataset's \textless{}ASTROTYPE\textgreater{}. Default is None and later determined by the Recipe
System based on the AstroDataType.

\item[{\textbf{-t \textless{}ASTROTYPE\textgreater{}, --astrotype \textless{}ASTROTYPE\textgreater{}}}] \leavevmode
Run a recipe based on this AstroDataType, which overrides default type or
begins without initial input. Eg., recipes that begin with primitives that
acquire data. \code{reduce} default is None and determined internally.

\item[{\textbf{--suffix \textless{}SUFFIX\textgreater{}}}] \leavevmode
Add `suffix' to output filenames at end of reduction.

\item[{\textbf{--throw\_descriptor\_exceptions}}] \leavevmode
Boolean indicating descriptor exceptions are to be raised. This is a
development switch.

\end{description}


\subsection{Nominal Usage}
\label{interfaces:nominal-usage}
The minimal call for reduce can be

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce \PYGZlt{}dataset.fits\PYGZgt{}
\end{Verbatim}

While this minimal call is available at the Gemini Observatory (see Sec.
{\hyperref[discuss:fitsstore]{\emph{Fits Storage}}}), if a calibration service is unavailable to the user --
likely true for most users -- users should call \code{reduce} on a specified
dataset by providing calibration files with the  --overrride\_cal option.

For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce \PYGZhy{}\PYGZhy{}override\PYGZus{}cal processed\PYGZus{}bias:FOO\PYGZus{}bias.fits \PYGZlt{}dataset.fits\PYGZgt{}
\end{Verbatim}

Such a command for complex processing of data is possible because AstroData
and the Recipe System do all the necessary work in determining how the data are to
be processed, which is critcially based upon the determination of the \emph{typeset}
that applies to that data.

Without any user-specified recipe (-r --recipe), the default recipe is
\code{qaReduce}, which is defined for various AstroDataTypes and currently used
during summit operations. The Recipe System uses a combination of index,
AstroDataTypes, and recipe naming convention to identify the appropriate
recipe to run.

The \code{qaReduce} recipe for a GMOS\_IMAGE, named \code{recipe.qaReduce.GMOS\_IMAGE},
specifies that the following primitives are called on the data

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{prepare}
\PYG{n}{addDQ}
\PYG{n}{addVAR}
\PYG{n}{detectSources}
\PYG{n}{measureIQ}
\PYG{n}{measureBG}
\PYG{n}{measureCCAndAstrometry}
\PYG{n}{overscanCorrect}
\PYG{n}{biasCorrect}
\PYG{n}{ADUToElectrons}
\PYG{n}{addVAR}
\PYG{n}{flatCorrect}
\PYG{n}{mosaicDetectors}
\PYG{n}{makeFringe}
\PYG{n}{fringeCorrect}
\PYG{n}{detectSources}
\PYG{n}{measureIQ}
\PYG{n}{measureBG}
\PYG{n}{measureCCAndAstrometry}
\PYG{n}{addToList}
\end{Verbatim}

The point here is not to overwhelm readers with a stack of primitive names, but
to present both the default pipeline processing that the above simple \code{reduce}
command invokes and to demonstrate how much the \code{reduce} interface abstracts
away the complexity of the processing that is engaged with the simplicity of
commands.


\subsection{Overriding Primitive Parameters}
\label{interfaces:userpars}\label{interfaces:overriding-primitive-parameters}
In some cases, users may wish to change the functional behaviour of certain
processing steps, i.e. change default behaviour of primitive
functions.

Each primitive has a set of pre-defined parameters, which are used to control
functional behaviour of the primitive. Each defined parameter has a ``user
override'' token, which indicates that a particular parameter may be overridden
by the user. Users can adjust parameter values from the reduce command line with
the option,
\begin{quote}

\textbf{-p, --param}
\end{quote}

If permitted by the ``user override'' token, parameters and values specified
through the \textbf{-p, --param} option will \emph{override} the defined
parameter default value and may alter default behaviour of the primitive
accessing this parameter. A user may pass several parameter-value pairs with
this option.

Eg.:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce \PYGZhy{}p par1=val1 par2=val2 [par3=val3 ... ] \PYGZlt{}fitsfile1.fits\PYGZgt{}
\end{Verbatim}

For example, some photometry primitives perform source detection on an image.
The `detection threshold' has a defined default, but a user may alter this
parameter default to change the source detection behaviour:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce \PYGZhy{}p threshold=4.5 \PYGZlt{}fitsfile.fits\PYGZgt{}
\end{Verbatim}


\subsection{The @file facility}
\label{interfaces:the-file-facility}\label{interfaces:atfile}
The reduce command line interface supports what might be called an `at-file'
facility (users and readers familiar with IRAF will recognize this facility).
This facility allows users to provide any and all command line options and flags
to \code{reduce} via in a single acsii text file.

By passing an @file to \code{reduce} on the command line, users can encapsulate all
the options and positional arguments they might wish to specify in a single
@file. It is possible to use multiple @files and even to embed one or more
@files in another. The parser opens all files sequentially and parses
all arguments in the same manner as if they were specified on the command line.
Essentially, an @file is some or all of the command line and parsed identically.

To illustrate the convenience provided by an \href{mailto:'@file}{`@file}`, let us begin with an
example \emph{reduce} command line that has a number of arguments:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce \PYGZhy{}p GMOS\PYGZus{}IMAGE:contextReport:tpar=100 GMOS\PYGZus{}IMAGE:contextReport:report\PYGZus{}inputs=True
  \PYGZhy{}r recipe.ArgsTest \PYGZhy{}\PYGZhy{}context qa S20130616S0019.fits N20100311S0090.fits
\end{Verbatim}

Ungainly, to be sure. Here, two (2) \emph{user parameters} are being specified
with \textbf{-p}, a \emph{recipe} with \textbf{-r}, and a \emph{context} argument is specified
to be \textbf{qa} . This can be wrapped in a plain text @file called
\emph{reduce\_args.par}:

\begin{Verbatim}[commandchars=\\\{\}]
S20130616S0019.fits
N20100311S0090.fits
\PYGZhy{}\PYGZhy{}param
GMOS\PYGZus{}IMAGE:contextReport:tpar=100
GMOS\PYGZus{}IMAGE:contextReport:report\PYGZus{}inputs=True
\PYGZhy{}r recipe.ArgsTests
\PYGZhy{}\PYGZhy{}context qa
\end{Verbatim}

This then turns the previous reduce command line into something a little more
\emph{keyboard friendly}:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce @reduce\PYGZus{}args.par
\end{Verbatim}

The order of these arguments is irrelevant. The parser will figure out what is
what. The above file could be thus written like:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZhy{}r recipe.ArgsTests
\PYGZhy{}\PYGZhy{}param
GMOS\PYGZus{}IMAGE:contextReport:tpar=100
GMOS\PYGZus{}IMAGE:contextReport:report\PYGZus{}inputs=True
\PYGZhy{}\PYGZhy{}context qa
S20130616S0019.fits
N20100311S0090.fits
\end{Verbatim}

Comments are accommodated, both as full line and in-line with the \code{\#}
character.  White space is the only significant separator of arguments: spaces,
tabs, newlines are all equivalent when argument parsing.  This means
the user can ``arrange'' their @file for clarity.

Here's a more readable version of the file from the previous example
using comments and tabulation:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZsh{} reduce parameter file
\PYGZsh{} yyyy\PYGZhy{}mm\PYGZhy{}dd
\PYGZsh{} GDPSG

\PYGZsh{} Spec the recipe
\PYGZhy{}r
    recipe.ArgsTests  \PYGZsh{} test recipe

\PYGZsh{} primitive parameters here
\PYGZsh{} These are \PYGZsq{}untyped\PYGZsq{}, i.e. global
\PYGZhy{}\PYGZhy{}param
    tpar=100
    report\PYGZus{}inputs=True

\PYGZhy{}\PYGZhy{}context
    qa                \PYGZsh{} QA context

S20130616S0019.fits
N20100311S0090.fits
\end{Verbatim}

All the above  examples of \code{reduce\_args.par} are equivalently parsed, which
users may check by adding the \textbf{-d} flag:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce \PYGZhy{}d @redpars.par

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}   switches, vars, vals  \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

Literals                      var \PYGZsq{}dest\PYGZsq{}              Value
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
[\PYGZsq{}\PYGZhy{}\PYGZhy{}invoked\PYGZsq{}]                 :: invoked              :: False
[\PYGZsq{}\PYGZhy{}\PYGZhy{}addprimset\PYGZsq{}]              :: primsetname          :: None
[\PYGZsq{}\PYGZhy{}d\PYGZsq{}, \PYGZsq{}\PYGZhy{}\PYGZhy{}displayflags\PYGZsq{}]      :: displayflags         :: True
[\PYGZsq{}\PYGZhy{}p\PYGZsq{}, \PYGZsq{}\PYGZhy{}\PYGZhy{}param\PYGZsq{}]             :: userparam            :: [\PYGZsq{}tpar=100\PYGZsq{}, \PYGZsq{}report\PYGZus{}inputs=True\PYGZsq{}]
[\PYGZsq{}\PYGZhy{}\PYGZhy{}logmode\PYGZsq{}]                 :: logmode              :: standard
[\PYGZsq{}\PYGZhy{}r\PYGZsq{}, \PYGZsq{}\PYGZhy{}\PYGZhy{}recipe\PYGZsq{}]            :: recipename           :: [\PYGZsq{}recipe.ArgTests\PYGZsq{}]
[\PYGZsq{}\PYGZhy{}\PYGZhy{}throw\PYGZus{}descriptor\PYGZus{}exceptions\PYGZsq{}] :: throwDescriptorExceptions        :: False
[\PYGZsq{}\PYGZhy{}\PYGZhy{}logfile\PYGZsq{}]                 :: logfile              :: reduce.log
[\PYGZsq{}\PYGZhy{}t\PYGZsq{}, \PYGZsq{}\PYGZhy{}\PYGZhy{}astrotype\PYGZsq{}]         :: astrotype            :: None
[\PYGZsq{}\PYGZhy{}\PYGZhy{}override\PYGZus{}cal\PYGZsq{}]            :: user\PYGZus{}cals            :: None
[\PYGZsq{}\PYGZhy{}\PYGZhy{}context\PYGZsq{}]                 :: running\PYGZus{}contexts     :: [\PYGZsq{}QA\PYGZsq{}]
[\PYGZsq{}\PYGZhy{}\PYGZhy{}calmgr\PYGZsq{}]                  :: cal\PYGZus{}mgr              :: None
[\PYGZsq{}\PYGZhy{}\PYGZhy{}suffix\PYGZsq{}]                  :: suffix               :: None
[\PYGZsq{}\PYGZhy{}\PYGZhy{}loglevel\PYGZsq{}]                :: loglevel             :: stdinfo
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

Input fits file(s):   S20130616S0019.fits
Input fits file(s):   N20100311S0090.fits
\end{Verbatim}


\subsection{Recursive @file processing}
\label{interfaces:recursive-file-processing}
As implemented, the @file facility will recursively handle, and process
correctly, other @file specifications that appear in a passed @file or
on the command line. For example, we may have another file containing a
list of fits files, separating the command line flags from the positional
arguments.

We have a plain text `fitsfiles' containing the line:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{test\PYGZus{}data}\PYG{o}{/}\PYG{n}{S20130616S0019}\PYG{o}{.}\PYG{n}{fits}
\end{Verbatim}

We can indicate that this file is to be consumed with the prefix character
``@'' as well. In this case, the `reduce\_args.par' file could thus appear:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZsh{} reduce test parameter file

@fitsfiles       \PYGZsh{} file with fits files

\PYGZsh{} AstroDataType
\PYGZhy{}t GMOS\PYGZus{}IMAGE

\PYGZsh{} primitive parameters.
\PYGZhy{}\PYGZhy{}param
    report\PYGZus{}inputs=True
    tpar=99
    FOO=BAR

\PYGZsh{} Spec the recipe
\PYGZhy{}r recipe.ArgTests
\end{Verbatim}

The parser will open and read the @fitsfiles, consuming those lines in the
same way as any other command line arguments. Indeed, such a file need not only
contain fits files (positional arguments), but other arguments as well. This is
recursive. That is, the @fitsfiles can contain other at-files'', which can contain
other ``at-files'', which can contain ..., etc. These will be processed
serially.

As stipulated earlier, because the @file facility provides arguments equivalent
to those that appear on the command line, employment of this facility means that
a reduce command line could assume the form:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce @parfile @fitsfiles
\end{Verbatim}

or equally:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce @fitsfiles @parfile
\end{Verbatim}

where `parfile' could contain the flags and user parameters, and `fitsfiles'
could contain a list of datasets.

Eg., fitsfiles comprises the one line:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{test\PYGZus{}data}\PYG{o}{/}\PYG{n}{N20100311S0090}\PYG{o}{.}\PYG{n}{fits}
\end{Verbatim}

while parfile holds all other specifications:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZsh{} reduce test parameter file
\PYGZsh{} GDPSG

\PYGZsh{} AstroDataType
\PYGZhy{}t GMOS\PYGZus{}IMAGE

\PYGZsh{} primitive parameters.
\PYGZhy{}\PYGZhy{}param
    report\PYGZus{}inputs=True
    tpar=99            \PYGZsh{} This is a test parameter
    FOO=BAR            \PYGZsh{} This is a test parameter

\PYGZsh{} Spec the recipe
\PYGZhy{}r recipe.ArgTests
\end{Verbatim}

The @file does not need to be located in the current directory.  Normal,
directory path syntax applies, for example:

\begin{Verbatim}[commandchars=\\\{\}]
reduce @../../mydefaultparams @fitsfile
\end{Verbatim}


\subsection{Overriding @file values}
\label{interfaces:overriding-file-values}
The \code{reduce} application employs a customized command line parser such that
the command line option

\textbf{-p} or \textbf{--param}

will accumulate a set of parameters \emph{or} override a particular parameter.
This may be seen when a parameter is specified in a user @file and then
specified on the command line. For unitary value arguments, the command line
value will \emph{override} the @file value.

It is further specified that if one or more datasets (i.e. positional arguments)
are passed on the command line, \emph{all fits files appearing as positional arguments}
\emph{in the parameter file will be replaced by the command line arguments.}

Using the parfile above,

Eg. 1)  Accumulate a new parameter:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce @parfile \PYGZhy{}\PYGZhy{}param FOO=BARSOOM

parsed options:
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
AstroDataType: GMOS\PYGZus{}IMAGE
FITS files:    [\PYGZsq{}S20130616S0019.fits\PYGZsq{}, \PYGZsq{}N20100311S0090.fits\PYGZsq{}]
Parameters:    tpar=100, report\PYGZus{}inputs=True, FOO=BARSOOM
RECIPE:        recipe.ArgsTest
\end{Verbatim}

Eg. 2) Override a parameter in the @file:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce @parfile \PYGZhy{}\PYGZhy{}param tpar=99

parsed options:
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
AstroDataType: GMOS\PYGZus{}IMAGE
FITS files:    [\PYGZsq{}S20130616S0019.fits\PYGZsq{}, \PYGZsq{}N20100311S0090.fits\PYGZsq{}]
Parameters:    tpar=99, report\PYGZus{}inputs=True
RECIPE:        recipe.ArgsTest
\end{Verbatim}

Eg. 3) Override the recipe:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce @parfile \PYGZhy{}r=recipe.FOO

parsed options:
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
AstroDataType: GMOS\PYGZus{}IMAGE
FITS files:    [\PYGZsq{}S20130616S0019.fits\PYGZsq{}, \PYGZsq{}N20100311S0090.fits\PYGZsq{}]
Parameters:    tpar=100, report\PYGZus{}inputs=True
RECIPE:        recipe.FOO
\end{Verbatim}

Eg. 4) Override a recipe and specify another fits file. The file names in
the @file will be ignored:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce @parfile \PYGZhy{}r=recipe.FOO test\PYGZus{}data/N20100311S0090\PYGZus{}1.fits

parsed options:
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
AstroDataType: GMOS\PYGZus{}IMAGE
FITS files:    [\PYGZsq{}test\PYGZus{}data/N20100311S0090\PYGZus{}1.fits\PYGZsq{}]
Parameters:    tpar=100, report\PYGZus{}inputs=True
RECIPE:        recipe.FOO
\end{Verbatim}


\section{Application Programming Interface (API)}
\label{interfaces:application-programming-interface-api}
\begin{notice}{note}{Note:}
This section describes and discusses the programmatic interface
available on the class Reduce.  This section is for advanced
users wishing to code using the \code{Reduce} class, rather than using
\code{reduce} at the command line.
\end{notice}

The \code{reduce} application is essentially a skeleton script providing the
described command line interface. After parsing the command line, the script
then passes the parsed arguments to its main() function, which in turn calls
the Reduce() class constructor with ``args''. The Reduce class is scriptable by
any user as the following discussion illustrates.


\subsection{Class Reduce, logging, and the runr() method}
\label{interfaces:class-reduce-logging-and-the-runr-method}
The Reduce class is defined under the \code{gemini\_python} code base in the
\code{recipe\_system.reduction} module, \code{coreReduce.py}.

The Reduce() class is importable and provides settable attributes and a callable
that can be used programmatically. Callers need not supply an ``args'' parameter
to the class initializer, i.e. \_\_init\_\_(). An instance of Reduce will have all
the same arguments as in a command line scenario, available as attributes on the
instance. Once an instance of Reduce() is instantiated and instance attributes
set as needed, there is one (1) method to call, \textbf{runr()}. This is the only
public method on the class.

Eg.,

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{recipe\PYGZus{}system.reduction.coreReduce} \PYG{k+kn}{import} \PYG{n}{Reduce}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce} \PYG{o}{=} \PYG{n}{Reduce}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{files}
\PYG{g+go}{[]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{files}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{S20130616S0019.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{files}
\PYG{g+go}{[\PYGZsq{}S20130616S0019.fits\PYGZsq{}]}
\end{Verbatim}

Or callers may simply set the \code{files} attribute to be an existing list of files

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{fits\PYGZus{}list} \PYG{o}{=} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{FOO.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{BAR.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{files} \PYG{o}{=} \PYG{n}{fits\PYGZus{}list}
\end{Verbatim}

On the command line, users may specify a recipe with the \code{-r} {[} \code{-{-}recipe} {]}
flag. Programmatically, users directly set the recipe:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{recipename} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{recipe.MyRecipe}\PYG{l+s}{\PYGZsq{}}
\end{Verbatim}

All other properties and  attributes on the API may be set in standard pythonic
ways. See Appendix
{\hyperref[appendices/reduce_properties:props]{\emph{Class Reduce: Settable properties and attributes}}} for further
discussion and more examples.


\subsubsection{Using the logger}
\label{interfaces:using-the-logger}
\begin{notice}{note}{Note:}
When using an instance of Reduce() directly, callers must configure
their own logger. Reduce() does not configure logutils prior to using
a logger as returned by logutils.get\_logger(). The following discussion
demonstrates how this is easily done. It is \emph{highly recommended}
that callers configure the logger.
\end{notice}

It is recommended that callers of Reduce use a logger supplied by the astrodata
module \code{logutils}. This module employs the python logger module, but with
recipe system specific features and embellishments. The recipe system
expects to have access to a logutils logger object, which callers should provide
prior to calling the \code{runr()} method.

To use \code{logutils}, import, configure, and get it:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{astrodata.utils} \PYG{k+kn}{import} \PYG{n}{logutils}
\PYG{n}{logutils}\PYG{o}{.}\PYG{n}{config}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{log} \PYG{o}{=} \PYG{n}{logutils}\PYG{o}{.}\PYG{n}{get\PYGZus{}logger}\PYG{p}{(}\PYG{n}{\PYGZus{}\PYGZus{}name\PYGZus{}\PYGZus{}}\PYG{p}{)}
\end{Verbatim}

where \code{\_\_name\_\_} is usually the calling module's \_\_name\_\_ property, but can
be any string value. Once configured and instantiated, the \code{log} object is
ready to use. See section {\hyperref[interfaces:options]{\emph{Configuration Switches, Options}}} for logging levels described on the
\code{-{-}loglevel} option.

Once an instance of Reduce has been made, callers may (should) configure the
logutils facility with attributes available on the instance. Instances of
\code{Reduce()} provide the following logger parameters as attributes on the
instance with appropriate default values:
\begin{itemize}\setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}
\item {} 
logfile

\item {} 
loglevel

\item {} 
logmode

\item {} 
logindent

\end{itemize}

The \code{reduce} command line provides access to the first three of these
attributes, as described in Sec. {\hyperref[interfaces:options]{\emph{Configuration Switches, Options}}}, but \code{logindent}, which
controls the indention levels of logging output, is accessible only through the
public interface on an instance of \code{Reduce()}. It is not anticipated that users
will need, or even want, to change the value of \code{logindent}, but it is possible.

An instance of \code{Reduce()} provides the following attributes that may be passed
to the \code{logutils.config()}. The default values provided for these logging
configuration parameters may be examined through direct inspection:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce} \PYG{o}{=} \PYG{n}{Reduce}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logfile}
\PYG{g+go}{\PYGZsq{}reduce.log\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logmode}
\PYG{g+go}{\PYGZsq{}standard\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{loglevel}
\PYG{g+go}{\PYGZsq{}stdinfo\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logindent}
\PYG{g+go}{3}
\end{Verbatim}

Users may adjust these values and then pass them to the \code{logutils.config()}
function, or pass other values directly to \code{config()}. This is precisely what
\code{reduce} does when it configures logutils. See Sec. {\hyperref[interfaces:options]{\emph{Configuration Switches, Options}}}  and
Appendix {\hyperref[appendices/reduce_properties:props]{\emph{Class Reduce: Settable properties and attributes}}} for
allowable and default values of these and other options.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{astrodata.utils} \PYG{k+kn}{import} \PYG{n}{logutils}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{logutils}\PYG{o}{.}\PYG{n}{config}\PYG{p}{(}\PYG{n}{file\PYGZus{}name}\PYG{o}{=}\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logfile}\PYG{p}{,} \PYG{n}{mode}\PYG{o}{=}\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logmode}\PYG{p}{,}
\PYG{g+go}{                    console\PYGZus{}lvl=reduce.loglevel)}
\end{Verbatim}

\begin{notice}{note}{Note:}
logutils.config() may be called mutliply, should callers, for example,
want to change logfile names for different calls on runr().
\end{notice}


\subsubsection{Call the runr() method}
\label{interfaces:call-the-runr-method}
Once a user is satisfied that all attributes are set to the desired values, and
the logger is configured, the runr() method on the ``reduce'' instance may then be
called. The following brings the examples above into one ``end-to-end'' use of
Reduce and logutils:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{recipe\PYGZus{}system.reduction.coreReduce} \PYG{k+kn}{import} \PYG{n}{Reduce}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{astrodata.utils} \PYG{k+kn}{import} \PYG{n}{logutils}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce} \PYG{o}{=} \PYG{n}{Reduce}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{files}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{S20130616S0019.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{recipename} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{recipe.MyRecipe}\PYG{l+s}{\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logfile} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{my\PYGZus{}reduce\PYGZus{}run.log}\PYG{l+s}{\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{logutils}\PYG{o}{.}\PYG{n}{config}\PYG{p}{(}\PYG{n}{file\PYGZus{}name}\PYG{o}{=}\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logfile}\PYG{p}{,} \PYG{n}{mode}\PYG{o}{=}\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logmode}\PYG{p}{,}
\PYG{g+go}{                    console\PYGZus{}lvl=reduce.loglevel)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{runr}\PYG{p}{(}\PYG{p}{)}
\PYG{g+go}{All submitted files appear valid}
\PYG{g+go}{Starting Reduction on set \PYGZsh{}1 of 1}
\PYG{g+go}{Processing dataset(s):}
\PYG{g+go}{S20130616S0019.fits}
\PYG{g+gp}{...}
\end{Verbatim}

Processing will then proceed in the usual manner. Astute readers will note that
callers need not create more than one Reduce instance in order to call runr()
with a different dataset or options.

Eg.,:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{recipe\PYGZus{}system.reduction.coreReduce} \PYG{k+kn}{import} \PYG{n}{Reduce}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{astrodata.utils} \PYG{k+kn}{import} \PYG{n}{logutils}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce} \PYG{o}{=} \PYG{n}{Reduce}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{files}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{S20130616S0019.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{recipename} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{recipe.MyRecipe}\PYG{l+s}{\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logfile} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{my\PYGZus{}reduce\PYGZus{}run.log}\PYG{l+s}{\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{logutils}\PYG{o}{.}\PYG{n}{config}\PYG{p}{(}\PYG{n}{file\PYGZus{}name}\PYG{o}{=}\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logfile}\PYG{p}{,} \PYG{n}{mode}\PYG{o}{=}\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logmode}\PYG{p}{,}
\PYG{g+go}{                     console\PYGZus{}lvl=reduce.loglevel)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{runr}\PYG{p}{(}\PYG{p}{)}
\PYG{g+go}{  ...}
\PYG{g+go}{reduce completed successfully.}

\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{recipename} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{recipe.NewRecipe}\PYG{l+s}{\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{files} \PYG{o}{=} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{newfile.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{userparam} \PYG{o}{=} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{clobber=True}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{runr}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

Once an attribute is set on an instance, such as above with \code{userparam}, it is
always set on the instance. If, on another call of runr() the caller does not
wish to have \code{clobber=True}, simply reset the property:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{userparam} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{runr}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

Readers may wish to examine the examples in Appendix
{\hyperref[appendices/reduce_properties:props]{\emph{Class Reduce: Settable properties and attributes}}}


\chapter{Supplemental tools}
\label{supptools:supplemental-tools}\label{supptools::doc}
The astrodata package provides a number of command line driven tools, which
users may find helpful in executing reduce on their data.

With the installation and configuration of \code{astrodata} and \code{reduce} comes
some supplemental tools to help users discover information, not only about their
own data, but about the Recipe System, such as available recipes, primitives,
and defined AstroDataTypes.

If the user environment has been configured correctly these applications
will work directly.


\section{listprimitives}
\label{supptools:listprimitives}
The application \code{listprimitives} is available as a command line executable.
This tool displays available primitives for all AstroDataTypes, their parameters,
and defaults. These are the parameters discussed in Sec. {\hyperref[interfaces:userpars]{\emph{Overriding Primitive Parameters}}} that
can be changed by the user with the \textbf{-p, --param} option on reduce. under the
AstroDataTypes. The help describes more options:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} listprimitives \PYGZhy{}h

Usage: listprimitives [options]

Gemini Observatory Primitive Inspection Tool, v1.0 2011

Options:
\PYGZhy{}h, \PYGZhy{}\PYGZhy{}help            show this help message and exit
\PYGZhy{}c, \PYGZhy{}\PYGZhy{}use\PYGZhy{}color       apply color output scheme
\PYGZhy{}i, \PYGZhy{}\PYGZhy{}info            show more information
\PYGZhy{}p, \PYGZhy{}\PYGZhy{}parameters      show parameters
\PYGZhy{}r, \PYGZhy{}\PYGZhy{}recipes         list top recipes
\PYGZhy{}s, \PYGZhy{}\PYGZhy{}primitive\PYGZhy{}set   show primitive sets (Astrodata types)
\PYGZhy{}v, \PYGZhy{}\PYGZhy{}verbose         set verbose mode
\PYGZhy{}\PYGZhy{}view\PYGZhy{}recipe=VIEW\PYGZus{}RECIPE
                      display the recipe
\end{Verbatim}


\subsection{listprimitives information}
\label{supptools:listprimitives-information}
The following section presents examples of the kind of information that
\code{listprimitives} may provide.

Show available recipes:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} listprimitives \PYGZhy{}r

===============================================================================

RECIPES\PYGZus{}Gemini
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
   1. basicQA
   2. checkQA
   3. makeProcessedArc.GMOS\PYGZus{}SPECT
   4. makeProcessedBias
   5. makeProcessedDark
   6. makeProcessedFlat
   7. makeProcessedFlat.GMOS\PYGZus{}IMAGE
   8. makeProcessedFlat.GMOS\PYGZus{}SPECT
   9. makeProcessedFlat.NIRI\PYGZus{}IMAGE
   10. makeProcessedFringe
   11. qaReduce.GMOS\PYGZus{}IMAGE
   12. qaReduce.GMOS\PYGZus{}SPECT
   13. qaReduce.NIRI\PYGZus{}IMAGE
   14. qaReduceAndStack.GMOS\PYGZus{}IMAGE
   15. qaStack.GMOS\PYGZus{}IMAGE
   16. reduce.F2\PYGZus{}IMAGE
   17. reduce.GMOS\PYGZus{}IMAGE

Subrecipes
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
   1. biasCorrect
   2. correctWCSToReferenceCatalog
   3. darkCorrect
   4. flatCorrect
   5. lampOnLampOff
   6. makeSky
   7. overscanCorrect
   8. prepare
   9. skyCorrect
   10. standardizeHeaders
   11. thermalEmissionCorrect

===============================================================================
\end{Verbatim}

Users can also display the contents of a particular recipe or subrecipe.
This will present the sequence of primitives that will be called by the
Recipe System when the particular recipe is either specified through the
\code{reduce} command line by the user, or selected internally by the Recipe System
itself.

For example, a user may like to see the primitive stack called by the default
`QA' recipe for GMOS\_IMAGE data. As seen in the above example, these `qa' recipes
are defined for several AstroDataTypes.

Show the primitive stack for the `qa' GMOS\_IMAGE type:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} listprimitives \PYGZhy{}\PYGZhy{}view\PYGZhy{}recipe qaReduce.GMOS\PYGZus{}IMAGE

===============================================================================
RECIPE: qaReduce.GMOS\PYGZus{}IMAGE
===============================================================================
\PYGZsh{} This recipe performs the standardization and corrections needed to convert
\PYGZsh{} the raw input science images into a single stacked science image

prepare
addDQ
addVAR(read\PYGZus{}noise=True)
detectSources
measureIQ(display=True)
measureBG
measureCCAndAstrometry
overscanCorrect
biasCorrect
ADUToElectrons
addVAR(poisson\PYGZus{}noise=True)
flatCorrect
mosaicDetectors
makeFringe
fringeCorrect
detectSources
measureIQ(display=True)
measureBG
measureCCAndAstrometry
addToList(purpose=forStack)


===============================================================================
\end{Verbatim}

\code{listprimitives} is in need of refinement and work continues on
building a tool that will present primitives and parameters in a more focused
way, i.e., report only those primitives and parameters relevant to a given
dataset. As it currently stands, users can request that \code{listprimitives}
display primitive parameters (as may be passed to \code{reduce} through the
\textbf{-p} or \textbf{--param} option, Sec. {\hyperref[interfaces:userpars]{\emph{Overriding Primitive Parameters}}}), but this results in a
list of all AstroDataTypes, their primitives and associated parameters.
Admittedly, this list is rather ungainly, but users may see, for example, that
the primitive \code{detectSources} has several user-tunable parameters:

\begin{Verbatim}[commandchars=\\\{\}]
detectSources
    suffix: \PYGZsq{}\PYGZus{}sourcesDetected\PYGZsq{}
    centroid\PYGZus{}function: \PYGZsq{}moffat\PYGZsq{}
    threshold: 3.0
    sigma: None
    fwhm: None
    method: \PYGZsq{}sextractor\PYGZsq{}
    max\PYGZus{}sources: 50
\end{Verbatim}

See the discussion in Sec. {\hyperref[interfaces:userpars]{\emph{Overriding Primitive Parameters}}} on command line override of
primitive parameters, and where overriding the `threshold' parameter is dicussed
specifically.


\section{typewalk}
\label{supptools:typewalk}\label{supptools:id1}
\code{typewalk} examines files in a directory or directory tree and reports the types
and status values through the AstroDataType classification scheme. Running \code{typewalk}
on a directory containing some Gemini datasets will demonstrate what users can expect
to see. If a user has downloaded gemini\_python X1 package with the `test\_data', the
user can move to this directory and run \code{typewalk} on that extensive set of
Gemini datasets.

By default, \code{typewalk} will recurse all subdirectories under the current
directory. Users may specify an explicit directory with the \textbf{-d} or
\textbf{--dir} option; the behavior remains recursive.

\code{typewalk} provides the following options {[}\textbf{-h, --help}{]}:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZhy{}h, \PYGZhy{}\PYGZhy{}help            show this help message and exit
\PYGZhy{}b BATCHNUM, \PYGZhy{}\PYGZhy{}batch BATCHNUM
                      In shallow walk mode, number of files to process at a
                      time in the current directory. Controls behavior in
                      large data directories. Default = 100.
\PYGZhy{}\PYGZhy{}calibrations        Show local calibrations (NOT IMPLEMENTED).
\PYGZhy{}c, \PYGZhy{}\PYGZhy{}color           Colorize display
\PYGZhy{}d TWDIR, \PYGZhy{}\PYGZhy{}dir TWDIR
                      Walk this directory and report types. default is cwd.
\PYGZhy{}f FILEMASK, \PYGZhy{}\PYGZhy{}filemask FILEMASK
                      Show files matching regex \PYGZlt{}FILEMASK\PYGZgt{}. Default is all
                      .fits and .FITS files.
\PYGZhy{}i, \PYGZhy{}\PYGZhy{}info            Show file meta information.
\PYGZhy{}\PYGZhy{}keys KEY [KEY ...]  Print keyword values for reported files.Eg., \PYGZhy{}\PYGZhy{}keys
                      TELESCOP OBJECT
\PYGZhy{}n, \PYGZhy{}\PYGZhy{}norecurse       Do not recurse subdirectories.
\PYGZhy{}\PYGZhy{}or                  Use OR logic on \PYGZsq{}types\PYGZsq{} criteria. If not specified,
                      matching logic is AND (See \PYGZhy{}\PYGZhy{}types). Eg., \PYGZhy{}\PYGZhy{}or \PYGZhy{}\PYGZhy{}types
                      GEMINI\PYGZus{}SOUTH GMOS\PYGZus{}IMAGE will report datasets that are
                      either GEMINI\PYGZus{}SOUTH *OR* GMOS\PYGZus{}IMAGE.
\PYGZhy{}o OUTFILE, \PYGZhy{}\PYGZhy{}out OUTFILE
                      Write reported files to this file. Effective only with
                      \PYGZhy{}\PYGZhy{}types option.
\PYGZhy{}\PYGZhy{}raise               Raise descriptor exceptions.
\PYGZhy{}\PYGZhy{}types TYPES [TYPES ...]
                      Find datasets that match only these type criteria.
                      Eg., \PYGZhy{}\PYGZhy{}types GEMINI\PYGZus{}SOUTH GMOS\PYGZus{}IMAGE will report
                      datasets that are both GEMINI\PYGZus{}SOUTH *and* GMOS\PYGZus{}IMAGE.
\PYGZhy{}\PYGZhy{}status              Report data processing status only.
\PYGZhy{}\PYGZhy{}typology            Report data typologies only.
\PYGZhy{}\PYGZhy{}xtypes XTYPES [[XTYPES ...]
                      Exclude \PYGZlt{}xtypes\PYGZgt{} from reporting.
\end{Verbatim}

Files are selected and reported through a regular expression mask which,
by default, finds all ''.fits'' and ''.FITS'' files. Users can change this mask
with the \textbf{-f, --filemask} option.

As the \textbf{--types} option indicates, \code{typewalk} can find and report data that
match specific type criteria. For example, a user might want to find all GMOS
image flats under a certain directory. \code{typewalk} will locate and report all
datasets that would match the AstroDataType, GMOS\_IMAGE\_FLAT.

A user may request that a file be written containing all datasets
matching AstroDataType qualifiers passed by the \textbf{--types} option. An output
file is specified through the \textbf{-o, --out} option. Output files are formatted
so they may be passed \emph{directly to the reduce command line} via that applications
`at-file' (@file) facility. See {\hyperref[interfaces:atfile]{\emph{The @file facility}}} or the reduce help for more on
`at-files'.

Users may select type matching logic with the \textbf{--or} switch. By default,
qualifying logic is AND, i.e. the logic specifies that \emph{all} types must be
present (x AND y); \textbf{--or} specifies that ANY types, enumerated with
\textbf{--types}, may be present (x OR y). \textbf{--or} is only effective when the
\textbf{--types} option is specified with more than one type.

For example, find all GMOS images from Cerro Pachon in the top level
directory and write out the matching files, then run reduce on them
(\textbf{-n} is `norecurse'):

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} typewalk \PYGZhy{}n \PYGZhy{}\PYGZhy{}types GEMINI\PYGZus{}SOUTH GMOS\PYGZus{}IMAGE \PYGZhy{}\PYGZhy{}out gmos\PYGZus{}images\PYGZus{}south
\PYGZdl{} reduce @gmos\PYGZus{}images\PYGZus{}south
\end{Verbatim}

Find all F2\_SPECT and GMOS\_SPECT datasets in a directory tree:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} typewalk \PYGZhy{}\PYGZhy{}or \PYGZhy{}\PYGZhy{}types GMOS\PYGZus{}SPECT F2\PYGZus{}SPECT
\end{Verbatim}

This will also report match results to stdout, colourized if requested (\textbf{-c}).

Users may find the \textbf{--xtypes} flag useful, as it provides a facility for
filtering results further by allowing certain types to be excluded from the
report.

For example, find GMOS\_IMAGE types, but exclude ACQUISITION images from reporting:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} typewalk \PYGZhy{}\PYGZhy{}types GMOS\PYGZus{}IMAGE \PYGZhy{}\PYGZhy{}xtypes ACQUISITION

directory: ../test\PYGZus{}data/output
   S20131010S0105.fits ............... (GEMINI) (GEMINI\PYGZus{}SOUTH) (GMOS) (GMOS\PYGZus{}IMAGE)
   (GMOS\PYGZus{}RAW) (GMOS\PYGZus{}S) (IMAGE) (RAW) (SIDEREAL) (UNPREPARED)

   S20131010S0105\PYGZus{}forFringe.fits ..... (GEMINI) (GEMINI\PYGZus{}SOUTH) (GMOS) (GMOS\PYGZus{}IMAGE)
   (GMOS\PYGZus{}S) (IMAGE) (NEEDSFLUXCAL) (OVERSCAN\PYGZus{}SUBTRACTED) (OVERSCAN\PYGZus{}TRIMMED)
   (PREPARED) (SIDEREAL)

   S20131010S0105\PYGZus{}forStack.fits ...... (GEMINI) (GEMINI\PYGZus{}SOUTH) (GMOS) (GMOS\PYGZus{}IMAGE)
   (GMOS\PYGZus{}S) (IMAGE) (NEEDSFLUXCAL) (OVERSCAN\PYGZus{}SUBTRACTED) (OVERSCAN\PYGZus{}TRIMMED)
   (PREPARED) (SIDEREAL)
\end{Verbatim}

Exclude GMOS\_IMAGE ACQUISITION images and GMOS\_IMAGE datasets that have been `prepared':

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} typewalk \PYGZhy{}\PYGZhy{}types GMOS\PYGZus{}IMAGE \PYGZhy{}\PYGZhy{}xtypes ACQUISITION PREPARED

directory: ../test\PYGZus{}data/output
   S20131010S0105.fits ............... (GEMINI) (GEMINI\PYGZus{}SOUTH) (GMOS) (GMOS\PYGZus{}IMAGE)
   (GMOS\PYGZus{}RAW) (GMOS\PYGZus{}S) (IMAGE) (RAW) (SIDEREAL) (UNPREPARED)
\end{Verbatim}

With \textbf{--types} and \textbf{--xtypes}, users may really tune their searches for very
specific datasets.


\chapter{Discussion}
\label{discuss:discussion}\label{discuss::doc}

\section{Fits Storage}
\label{discuss:fits-storage}\label{discuss:fitsstore}
The URLs that appear in \code{test\_one} recipe example (Sec. {\hyperref[userenv:test]{\emph{Test the installation}}}), reference web services
available within the Gemini Observatory's operational environment. They will
\emph{not} be available directly to users running \code{reduce} outside of the Gemini
Observatory environment.

In the context of \code{reduce} and the Astrodata Recipe System, FitsStorage provides
a calibration management and association feature. Essentially, given a science
frame (or any frame that requires calibration) and a calibration
type requested, FitsStorage is able to automatically choose the best available
calibration of the required type to apply to the science frame. The Recipe System
uses a machine-oriented calibration manager interface in order to select
calibration frames to apply as part of pipeline processing.

Though this service is not currently available to general gemini\_python users,
plans to provide this as a local calibration service are in place and expected
for {\hyperref[discuss:future]{\emph{Future Enhancements}}}.


\section{The adcc}
\label{discuss:adcc}\label{discuss:the-adcc}
As a matter of operations, \code{reduce} and the Recipe System depend upon the
services of what is called the \code{adcc}, the Automated Data Communication Center.
The \code{adcc} provides services to pipeline operations through two proxy servers,
an XML-RPC server and an HTTP server. The XML\_RPC server serves calibration
requests made on it, and retrieves calibrations that satisfiy those requests
from the Gemini FITS Store, a service that provides automated calibration
lookup and retrieval.

The \code{adcc} can be run externally and will run continuously until it is
shutdown. Any instances of \code{reduce} (and the Recipe System) will employ
this external instance of the \code{adcc} to service a pipeline's calibration
requests. However, a user of \code{reduce} need not start an instance of the
\code{adcc} nor, indeed, know anytihng about the \code{adcc} \emph{per se}. If one is not
available, an instance of the \code{adcc} will be started by \code{reduce} itself,
and will serve that particular \code{reduce} process and then terminate.

This note is provided should users notice an \code{adcc} process and wonder what
it is.


\section{Future Enhancements}
\label{discuss:future}\label{discuss:future-enhancements}

\subsection{Intelligence}
\label{discuss:intelligence}
One enhancement long imagined is what has been generally termed `intelligence'.
That is, an ability for either \code{reduce} or some utility to automatically do
AstroDataType classification of a set of data, group them appropriately, and
then pass these grouped data to the Recipe System.

As things stand now, it is up to the user to pass commonly typed data to
\code{reduce}. As shown in the previous section, {\hyperref[supptools:typewalk]{\emph{typewalk}}}, \code{typewalk}
can help a user perform this task and create a `ready-to-run' @file that can
be passed directly to \code{reduce}. Properly implemented `intelligence' will
\emph{not} require the user to determine the AstroDataTypes of datasets.


\subsection{Local Calibration Service}
\label{discuss:local-calibration-service}
The Fits Storage service will be delivered as part of a future release and will
provide the calibration management and association features of {\hyperref[discuss:fitsstore]{\emph{Fits Storage}}}: for
use with the public release of the \emph{gemini\_python} data reduction package. This
feature will provide automatic calibration selection for both pipeline (recipe)
operations and in an interactive processing environment.


\chapter{6. Acknowledgments}
\label{ack::doc}\label{ack:acknowledgments}
The Gemini Observatory is operated by the Association of Universities for
Research in Astronomy (AURA), Inc., under a cooperative agreement with the NSF on
behalf of the Gemini partnership: the National Science Foundation
(United States), the Science and Technology Facilities Council (United Kingdom),
the National Research Council (Canada), CONICYT (Chile), the Australian
Research Council (Australia), Ministerio da Ciencia e Tecnologia (Brazil),
and Ministerio de Ciencia, Tecnologia e Innovacion Productiva (Argentina).
% Set up the appendix mode and modify the LaTeX toc behavior
\appendix
\noappendicestocpagenum
\addappheadtotoc

\chapter{\emph{reduce} demo}
\label{appendices/appendix_demo::doc}\label{appendices/appendix_demo:reduce-demo}
Original demo author: Kathleen Labrie, October 2014


\section{Setting up}
\label{appendices/appendix_demo:setting-up}
First install Ureka, which can be obtained at \href{http://ssb.stsci.edu/ureka/}{http://ssb.stsci.edu/ureka/}.

The second step is to install \code{gemini\_python} as described in
{\hyperref[userenv:config]{\emph{Section 2 - Installation}}}.
Please do make sure that the command \emph{reduce} is in your \code{PATH} and that
\code{PYTHONPATH} includes the location where the modules \code{astrodata}, \code{astrodata\_FITS},
\code{astrodata\_Gemini}, and \code{gempy} are installed.

The demo data is distributed separately.  You can find the demo data package
\code{gemini\_python\_datapkg-X1.tar.gz} on the Gemini website where you found the
gemini\_python package.  Unpack the data package somewhere convenient:

\begin{Verbatim}[commandchars=\\\{\}]
tar xvzf gemini\PYGZus{}python\PYGZus{}datapkg\PYGZhy{}X1.tar.gz
\end{Verbatim}

In there, you will find a subdirectory named \code{data\_for\_reduce\_demo}.  Those are
the data we will use here.  You will also find an empty directory called
\code{playground}.  This is your playground. The instructions in this demo assume that
you are running the \code{reduce} command from that directory.  There is no requirements
to run \code{reduce} from that directory, but if you want to follow the demo to the
letter, this is where you should be for all the paths to work.


\section{Introduction to the Demo}
\label{appendices/appendix_demo:introduction-to-the-demo}
In this demo, we will reduce a simple dither-on-source GMOS imaging sequence.
We will first process the raw biases, and then the raw twilight flats.  We will
then use those processed files to process and stack the science observation.

Instead of the default Quality Assessment (QA) recipe that is used at the Gemini
summits, we will use another recipe that will focus on the reduction rather
than on the multiple measurements of the QA metrics used at night.  QA metrics,
here the image quality (IQ), will only be measured at the end of the reduction
rather than throughout the reduction.   Another difference between the standard
QA recipe and the demo recipe, is that the demo recipe does stack the data, while
the stacking is turned off in the QA context.

The demo recipe is essentially a Quick Look recipe.  It is NOT valid for Science
Quality.  Remember that what you are using is a QA pipeline, not a Science pipeline.


\section{The Recipes}
\label{appendices/appendix_demo:the-recipes}
To process the biases and the flats we will be using the standard recipes. The
system will be able to pick those automatically when it recognizes the input data
as GMOS biases and GMOS twilight flats.

For the science data, we will override the recipe selection to use the Demo recipe.
If we were not to override the recipe selection, the system would automatically
select the QA recipe.  The Demo recipe is more representative of a standard
Quick-Look reduction with stacking, hence probably more interesting to the reader.

The standard recipe to process GMOS biases is named \code{recipe.makeProcessedBias}
and contains these instructions:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c}{\PYGZsh{} This recipe performs the standardization and corrections needed to convert}
\PYG{c}{\PYGZsh{} the raw input bias images into a single stacked bias image. This output}
\PYG{c}{\PYGZsh{} processed bias is stored on disk using storeProcessedBias and has a name}
\PYG{c}{\PYGZsh{} equal to the name of the first input bias image with \PYGZdq{}\PYGZus{}bias.fits\PYGZdq{} appended.}

\PYG{n}{prepare}
\PYG{n}{addDQ}
\PYG{n}{addVAR}\PYG{p}{(}\PYG{n}{read\PYGZus{}noise}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}
\PYG{n}{overscanCorrect}
\PYG{n}{addToList}\PYG{p}{(}\PYG{n}{purpose}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{forStack}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{getList}\PYG{p}{(}\PYG{n}{purpose}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{forStack}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{stackFrames}
\PYG{n}{storeProcessedBias}
\end{Verbatim}

The standard recipe to process GMOS twilight flats is named
\code{recipe.makeProcessedFlat.GMOS\_IMAGE} and contains these instructions:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c}{\PYGZsh{} This recipe performs the standardization and corrections needed to convert}
\PYG{c}{\PYGZsh{} the raw input flat images into a single stacked and normalized flat image.}
\PYG{c}{\PYGZsh{} This output processed flat is stored on disk using storeProcessedFlat and}
\PYG{c}{\PYGZsh{} has a name equal to the name of the first input flat image with \PYGZdq{}\PYGZus{}flat.fits\PYGZdq{}}
\PYG{c}{\PYGZsh{} appended.}

\PYG{n}{prepare}
\PYG{n}{addDQ}
\PYG{n}{addVAR}\PYG{p}{(}\PYG{n}{read\PYGZus{}noise}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}
\PYG{n}{display}
\PYG{n}{overscanCorrect}
\PYG{n}{biasCorrect}
\PYG{n}{ADUToElectrons}
\PYG{n}{addVAR}\PYG{p}{(}\PYG{n}{poisson\PYGZus{}noise}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}
\PYG{n}{addToList}\PYG{p}{(}\PYG{n}{purpose}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{forStack}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{getList}\PYG{p}{(}\PYG{n}{purpose}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{forStack}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{stackFlats}
\PYG{n}{normalizeFlat}
\PYG{n}{storeProcessedFlat}
\end{Verbatim}

The Demo recipe is named \code{recipe.reduceDemo} and contains these instructions:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c}{\PYGZsh{} recipe.reduceDemo}

\PYG{n}{prepare}
\PYG{n}{addDQ}
\PYG{n}{addVAR}\PYG{p}{(}\PYG{n}{read\PYGZus{}noise}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}
\PYG{n}{overscanCorrect}
\PYG{n}{biasCorrect}
\PYG{n}{ADUToElectrons}
\PYG{n}{addVAR}\PYG{p}{(}\PYG{n}{poisson\PYGZus{}noise}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}
\PYG{n}{flatCorrect}
\PYG{n}{makeFringe}
\PYG{n}{fringeCorrect}
\PYG{n}{mosaicDetectors}
\PYG{n}{detectSources}
\PYG{n}{addToList}\PYG{p}{(}\PYG{n}{purpose}\PYG{o}{=}\PYG{n}{forStack}\PYG{p}{)}
\PYG{n}{getList}\PYG{p}{(}\PYG{n}{purpose}\PYG{o}{=}\PYG{n}{forStack}\PYG{p}{)}
\PYG{n}{alignAndStack}
\PYG{n}{detectSources}
\PYG{n}{measureIQ}
\end{Verbatim}

For the curious, the standard bias and flat recipes are found in
\code{astrodata\_Gemini/RECIPES\_Gemini/} and the demo recipe is in
\code{astrodata\_Gemini/RECIPES\_Gemini/demos/}.  You do not really need that information
as the system will find them on its own.


\section{The Demo}
\label{appendices/appendix_demo:the-demo}
The images will be displayed at times.  Therefore, start ds9:

\begin{Verbatim}[commandchars=\\\{\}]
ds9 \PYGZam{}
\end{Verbatim}


\subsection{The Processed Bias}
\label{appendices/appendix_demo:the-processed-bias}
The first step is to create the processed bias.  We are using the standard
recipe.  The system will recognize the inputs as GMOS biases and call the
appropriate recipe automatically.

The biases were taken on different dates
around the time of the science observations.  For convenience, we will use
a file with the list of datasets as input instead of listing all the input
datasets individually.  We will use a tool named \code{typewalk} to painlessly
create the list.

\begin{Verbatim}[commandchars=\\\{\}]
cd \PYGZlt{}your\PYGZus{}path\PYGZgt{}/gemini\PYGZus{}python\PYGZus{}datapkg\PYGZhy{}X1/playground

typewalk \PYGZhy{}\PYGZhy{}types GMOS\PYGZus{}BIAS \PYGZhy{}\PYGZhy{}dir ../data\PYGZus{}for\PYGZus{}reduce\PYGZus{}demo \PYGZhy{}o bias.list

reduce @bias.list
\end{Verbatim}

This creates the processed bias, \code{N20120202S0955\_bias.fits}.  The output suffix
\code{\_bias} is the indicator that this is a processed bias.  All processed calibrations
are also stored in \code{./calibrations/storedcals/} for safe keeping.

If you wish to see what the processed bias looks like:

\begin{Verbatim}[commandchars=\\\{\}]
reduce N20120202S0955\PYGZus{}bias.fits \PYGZhy{}r display
\end{Verbatim}

\emph{Note: This will issue an error about the file already existing.  Ignore it.
The explanation of what is going on is beyond the scope of this demo.  We
will fix this, eventually.  Remember that this is a release of software meant
for internal use; there are still plenty of issues to be resolved.}


\subsection{The Processed Flat}
\label{appendices/appendix_demo:the-processed-flat}
Next we create a processed flat.  We will use the processed bias we have
just created.  The system will recognize the inputs as GMOS twilight flats and
call the appropriate recipe automatically.

The ``public'' RecipeSystem does not yet have a Local Calibration Server.  Therefore,
we will need to specify the processed bias we want to use on the \emph{reduce} command
line.  For information only, internally the QA pipeline at the summit uses a
central calibration server and the most appropriate processed calibrations available
are selected and retrieved automatically.  We hope to be able to offer a ``local'',
end-user version of this system in the future.  For now, calibrations must be
specified on the command line.

For the flats, we do not really need a list, we can use wild cards:

\begin{Verbatim}[commandchars=\\\{\}]
reduce ../data\PYGZus{}for\PYGZus{}reduce\PYGZus{}demo/N20120123*.fits \PYGZbs{}
   \PYGZhy{}\PYGZhy{}override\PYGZus{}cal processed\PYGZus{}bias:N20120202S0955\PYGZus{}bias.fits \PYGZbs{}
   \PYGZhy{}p clobber=True
\end{Verbatim}

This creates the processed flat, \code{N20120123S0123\_flat.fits}.  The output suffix
\code{\_flat} is the indictor that this is a processed flat.  The processed flat is also
stored in \code{./calibrations/storedcals/} for safe keeping.

The \code{clobber} parameter is set to True to allow the system to overwrite the final
output.  By default, the system refuses to overwrite an output file.

If you wish to see what the processed flat looks like:

\begin{Verbatim}[commandchars=\\\{\}]
reduce N20120123S0123\PYGZus{}flat.fits \PYGZhy{}r display
\end{Verbatim}


\subsection{The Science Frames}
\label{appendices/appendix_demo:the-science-frames}
We now have all the pieces required to reduce the science frames.  This time,
instead of using the standard QA recipe, we will use the Demo recipe.  Again,
we will specify the processed calibrations, bias and flat, we wish to use.

\begin{Verbatim}[commandchars=\\\{\}]
reduce ../data\PYGZus{}for\PYGZus{}reduce\PYGZus{}demo/N20120203S028?.fits \PYGZbs{}
   \PYGZhy{}\PYGZhy{}override\PYGZus{}cal processed\PYGZus{}bias:N20120202S0955\PYGZus{}bias.fits \PYGZbs{}
                  processed\PYGZus{}flat:N20120123S0123\PYGZus{}flat.fits \PYGZbs{}
   \PYGZhy{}r reduceDemo \PYGZbs{}
   \PYGZhy{}p clobber=True
\end{Verbatim}

The demo data was obtained with the z' filter, therefore the images contain fringing.
The \code{makeFringe} and \code{fringeCorrect} primitives are filter-aware, they will do
something only when the data is from a filter that produces fringing, like the z'
filter.  The processed fringe that is created is stored with the other processed
calibrations in \code{./calibrations/storedcals/} and it is named \code{N20120203S0281\_fringe.fits}.
The \code{\_fringe} suffix indicates a processed fringe.

The last primitive in the recipe is \code{measureIQ} which is one of the QA metrics
primitives used at night by the QA pipeline.  The primitive selects stars in
the field and measures the average seeing and ellipticity.  The image it runs
on is displayed and the selected stars are circled for visual inspections.

The fully processed stacked science image is \code{N20120203S0281\_iqMeasured.fits}.
By default, the suffix of the final image is set by the last primitive run
on the data, in this case \code{measureIQ}.

This default naming can be confusing.  If you wish to set the suffix of the
final image yourself, use \code{-{-}suffix  \_myfinalsuffix}.


\subsection{Clean up}
\label{appendices/appendix_demo:clean-up}
It is good practice to reset the RecipeSystem state when you are done:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{superclean} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{safe}
\end{Verbatim}

Your files will stay there, only some hidden RecipeSystem directories
and files will be deleted.


\section{Limitations}
\label{appendices/appendix_demo:limitations}
The X1 version of the RecipeSystem has not been vetted for Science Quality.
Use ONLY for quick look purposes.

The RecipeSystem currently does not handle memory usage in a very smart way.
The number of files one can pass on to \code{reduce} is directly limited by the
memory of the user's computer.  This demo ran successfully on a Mac laptop
with 4 GB of memory.


\chapter{Class Reduce: Settable properties and attributes}
\label{appendices/reduce_properties:class-reduce-settable-properties-and-attributes}\label{appendices/reduce_properties::doc}\label{appendices/reduce_properties:props}
The public interface on an instance of the Reduce() class provides a
number of properties and attributes that allow the user to set and reset
options as they might through the reduce command line interface. The following
table is an enumerated set of those attributes.

An instance of Reduce() provides the following attributes. (Note: defaults
are not necessarily indicative of the actual type that is expected on
the instance. Use the type specified in the type column.):

\begin{Verbatim}[commandchars=\\\{\}]
Attribute                  Python type         Default
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
astrotype                  \PYGZlt{}type \PYGZsq{}str\PYGZsq{}\PYGZgt{}         None
cal\PYGZus{}mgr                    \PYGZlt{}type \PYGZsq{}str\PYGZsq{}\PYGZgt{}         None
displayflags               \PYGZlt{}type \PYGZsq{}bool\PYGZsq{}\PYGZgt{}        False
files                      \PYGZlt{}type \PYGZsq{}list\PYGZsq{}\PYGZgt{}        []
invoked                    \PYGZlt{}type \PYGZsq{}bool\PYGZsq{}\PYGZgt{}        False
logfile                    \PYGZlt{}type \PYGZsq{}str\PYGZsq{}\PYGZgt{}         \PYGZsq{}reduce.log\PYGZsq{}
loglevel                   \PYGZlt{}type \PYGZsq{}str\PYGZsq{}\PYGZgt{}         \PYGZsq{}stdinfo\PYGZsq{}
logmode                    \PYGZlt{}type \PYGZsq{}str\PYGZsq{}\PYGZgt{}         \PYGZsq{}standard\PYGZsq{}
primsetname                \PYGZlt{}type \PYGZsq{}str\PYGZsq{}\PYGZgt{}         None
recipename                 \PYGZlt{}type \PYGZsq{}str\PYGZsq{}\PYGZgt{}         None
running\PYGZus{}contexts           \PYGZlt{}type \PYGZsq{}str\PYGZsq{}\PYGZgt{}         None
suffix                     \PYGZlt{}type \PYGZsq{}str\PYGZsq{}\PYGZgt{}         None
throwDescriptorExceptions  \PYGZlt{}type \PYGZsq{}bool\PYGZsq{}\PYGZgt{}        False
user\PYGZus{}cals                  \PYGZlt{}type \PYGZsq{}str\PYGZsq{}\PYGZgt{}         None
userparam                  \PYGZlt{}type \PYGZsq{}list\PYGZsq{}\PYGZgt{}        None
\end{Verbatim}


\section{Examples}
\label{appendices/reduce_properties:examples}
Setting attributes on a Reduce object:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce} \PYG{o}{=} \PYG{n}{Reduce}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logfile} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{my\PYGZus{}reduction.log}\PYG{l+s}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{recipe} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{recipe.my\PYGZus{}recipe}\PYG{l+s}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{files} \PYG{o}{=} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{UVW.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{XYZ.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
\end{Verbatim}

Or in other pythonic ways:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}list} \PYG{o}{=} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{FOO.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{BAR.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{files}\PYG{o}{.}\PYG{n}{extend}\PYG{p}{(}\PYG{n}{file\PYGZus{}list}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{files}
\PYG{g+go}{[\PYGZsq{}UVW.fits\PYGZsq{}, \PYGZsq{}XYZ.fits\PYGZsq{}, \PYGZsq{}FOO.fits\PYGZsq{}, \PYGZsq{}BAR.fits\PYGZsq{}]}
\end{Verbatim}

Users wishing to pass primtive parameters to the recipe\_system need only set
the one (1) attribute, \code{userparam}, on the Reduce instance:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{userparam} \PYG{o}{=} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{clobber=True}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
\end{Verbatim}

This is the API equivalent to the command line option:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce \PYGZhy{}p clobber=True [...]
\end{Verbatim}

For muliple primitive parameters, the `userparam' attribute is a list of
`par=val' strings, as in:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{userparam} \PYG{o}{=} \PYG{p}{[} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{par1=val1}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{par2=val2}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.} \PYG{p}{]}
\end{Verbatim}


\section{Example function}
\label{appendices/reduce_properties:example-function}
The following function shows a potential usage of class Reduce. When
conditions are met, the function \code{reduce\_conditions\_met()} is called
passing several lists of files, \code{procfiles} (a list of lists of fits
files). Here, each list of \code{procfiles} is then passed to the internal
\code{launch\_reduce()} function.

\begin{Verbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{k+kn}{from} \PYG{n+nn}{astrodata.utils} \PYG{k+kn}{import} \PYG{n}{logutils}
\PYG{k+kn}{from} \PYG{n+nn}{recipe\PYGZus{}system.reduction.coreReduce} \PYG{k+kn}{import} \PYG{n}{Reduce}

\PYG{k}{def} \PYG{n+nf}{reduce\PYGZus{}conditions\PYGZus{}are\PYGZus{}met}\PYG{p}{(}\PYG{n}{procfiles}\PYG{p}{,} \PYG{n}{control\PYGZus{}options}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{reduce\PYGZus{}object} \PYG{o}{=} \PYG{n}{Reduce}\PYG{p}{(}\PYG{p}{)}
    \PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{logfile} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{my\PYGZus{}reduce.log}\PYG{l+s}{\PYGZsq{}}
    \PYG{c}{\PYGZsh{} write logfile only, no stdout.}
    \PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{logmode} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{quiet}\PYG{l+s}{\PYGZsq{}}
    \PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{userparam} \PYG{o}{=} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{clobber=True}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}

    \PYG{n}{logutils}\PYG{o}{.}\PYG{n}{config}\PYG{p}{(}\PYG{n}{file\PYGZus{}name}\PYG{o}{=}\PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{logfile}\PYG{p}{,}
                    \PYG{n}{mode}\PYG{o}{=}\PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{logmode}\PYG{p}{,}
                    \PYG{n}{console\PYGZus{}lvl}\PYG{o}{=}\PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{loglevel}\PYG{p}{)}

    \PYG{k}{def} \PYG{n+nf}{launch\PYGZus{}reduce}\PYG{p}{(}\PYG{n}{datasets}\PYG{p}{,} \PYG{n}{recipe}\PYG{o}{=}\PYG{n+nb+bp}{None}\PYG{p}{,} \PYG{n}{upload}\PYG{o}{=}\PYG{n+nb+bp}{False}\PYG{p}{)}\PYG{p}{:}
        \PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{files} \PYG{o}{=} \PYG{n}{datasets}
        \PYG{k}{if} \PYG{n}{recipe}\PYG{p}{:}
            \PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{recipename} \PYG{o}{=} \PYG{n}{recipe}
        \PYG{k}{if} \PYG{n}{upload}\PYG{p}{:}
            \PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{running\PYGZus{}contexts} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{upload}\PYG{l+s}{\PYGZsq{}}
        \PYG{k}{else}\PYG{p}{:}
            \PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{running\PYGZus{}contexts} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{qa}\PYG{l+s}{\PYGZsq{}}
        \PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{runr}\PYG{p}{(}\PYG{p}{)}
        \PYG{k}{return}

    \PYG{k}{for} \PYG{n}{files} \PYG{o+ow}{in} \PYG{n}{procfiles}\PYG{p}{:}
        \PYG{c}{\PYGZsh{} Use a different recipe if FOO.fits is present}
        \PYG{k}{if} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{FOO.fits}\PYG{l+s}{\PYGZdq{}} \PYG{o+ow}{in} \PYG{n}{files}\PYG{p}{:}
            \PYG{n}{launch\PYGZus{}reduce}\PYG{p}{(}\PYG{n+nb}{sorted}\PYG{p}{(}\PYG{n}{files}\PYG{p}{)}\PYG{p}{,} \PYG{n}{recipe}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{recipe.FOO}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
        \PYG{k}{else}\PYG{p}{:}
            \PYG{n}{launch\PYGZus{}reduce}\PYG{p}{(}\PYG{n+nb}{sorted}\PYG{p}{(}\PYG{n}{files}\PYG{p}{)}\PYG{p}{,} \PYG{n}{upload}\PYG{o}{=}\PYG{n}{control\PYGZus{}options}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{upload}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}

    \PYG{k}{return}

\PYG{n}{procfiles} \PYG{o}{=} \PYG{p}{[} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{FOO.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{BAR.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,}
              \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{UVW.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{XYZ.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
           \PYG{p}{]}
\PYG{k}{if} \PYG{n}{conditions\PYGZus{}are\PYGZus{}met}\PYG{p}{:}
    \PYG{n}{reduce\PYGZus{}conditions\PYGZus{}are\PYGZus{}met}\PYG{p}{(}\PYG{n}{procfiles}\PYG{p}{)}
\end{Verbatim}

Readers will see here that calling \code{reduce\_conditions\_are\_met()} without the
\code{control\_options} parameter will result in the \code{running\_contexts} attribute
being set to \code{'qa'}.



\renewcommand{\indexname}{Index}
\printindex
\end{document}
